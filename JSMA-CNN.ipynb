{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1dc2aa02447f811c6f03ee20f89d3d0a555781ac6ddb7a2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as  sns\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import ADASYN,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming you have your data in a DataFrame with features in 'X' and target in 'y'\n",
    "# Replace this with your actual data loading process\n",
    "df= pd.read_csv('/media/masharifin/D Drive/ComprehensiveExam/Datasets/CIC-Malmem/New/newmalwaredata80.csv')\n",
    "#df['Class'] = df['Class'].replace({'Benign': 0, 'Malware': 1})\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired number of samples for both class 0 and class 1 (e.g., 1000 each)\n",
    "desired_samples_class_0 = 29298\n",
    "desired_samples_class_1 = 29298\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy={0: desired_samples_class_0, 1: desired_samples_class_1}, random_state=42)\n",
    "\n",
    "# Apply Random Oversampling to generate exactly 1000 synthetic samples for each class\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# The resampled data will be in X_resampled and y_resampled\n",
    "# Now you can use this resampled data for training your model\n",
    "# Convert the resampled data back to a DataFrame\n",
    "resampled_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "resampled_data['Class'] = y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resampled data to a new CSV file\n",
    "resampled_data.to_csv('/media/masharifin/D Drive/ComprehensiveExam/Datasets/resampled_data_randomsample.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.read_csv('/media/masharifin/D Drive/ComprehensiveExam/Datasets/resampled_data_randomsample.csv')\n",
    "#dr['Class'] = dr['Class'].replace({'Benign': 0, 'Malware': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d36824",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.read_csv('/media/masharifin/D Drive/ComprehensiveExam/Datasets/CIC-Malmem/ObfuscatedMalMem2022.csv')\n",
    "dc['Class'] = dr['Class'].replace({'Benign': 0, 'Malware': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77864b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example visualization: Histogram\n",
    "plt.hist(dc['pslist.avg_handlers'], bins=20)\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of column_name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example visualization: Histogram\n",
    "plt.hist(dr['pslist.avg_handlers'], bins=20)\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of column_name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5370798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Generate heatmap\n",
    "plt.figure(figsize=(10, 8))  # Set the size of the heatmap\n",
    "sns.heatmap(dc.corr(), annot=True, cmap='magma', fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap\")  # Set the title of the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of columns to drop\n",
    "# columns_to_drop_dc = ['ldrmodules.not_in_init_avg', 'ldrmodules.not_in_load_avg', 'ldrmodules.not_in_mem_avg']\n",
    "\n",
    "# # Drop the specified columns\n",
    "# dc.drop(columns=columns_to_drop_dc, inplace=True)\n",
    "\n",
    "# dc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6284f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of columns to drop\n",
    "# columns_to_drop_dr = ['apihooks.nhooks', 'apihooks.nhooksInline', 'apihooks.nhooksUsermode']\n",
    "\n",
    "# # Drop the specified columns\n",
    "# dr.drop(columns=columns_to_drop_dr, inplace=True)\n",
    "\n",
    "# dr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dc.drop('Class', axis=1).values\n",
    "Class = dc['Class'].values\n",
    "X_train=dc.drop(columns='Class')\n",
    "y_train=dc['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dr.drop('Class', axis=1).values\n",
    "Class = dr['Class'].values\n",
    "X_test=dr.drop(columns='Class')\n",
    "y_test=dr['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_shuffled, y_shuffled = shuffle(x, y, random_state=42)\n",
    "# train_size = 0.7\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_shuffled, y_shuffled, train_size=train_size, random_state=42)\n",
    "# print(\"Train set size:\", X_train.shape[0])\n",
    "# print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=['Benign','Malicious'], columns=['Benign','Malicious'])\n",
    "    cm.index.name = 'Actual Attack'\n",
    "    cm.columns.name = 'Predicted Attack'\n",
    "    #cm.labels.name=['No','Yes']\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    sns.heatmap(cm, cmap= 'Reds',cbar=False, annot=annot,fmt='', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3edd4",
   "metadata": {},
   "source": [
    "# Random Model_7:CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1dc2aa02447f811c6f03ee20f89d3d0a555781ac6ddb7a2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape X_train and X_test to be 3D tensors for CNN\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Create the CNN model\n",
    "model_cnn = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model_cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model_cnn.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Add fully connected layers\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(units=128, activation='relu'))\n",
    "model_cnn.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy_cnn = model_cnn.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test accuracy: {accuracy_cnn:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c129a",
   "metadata": {},
   "source": [
    "# Attack On CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and compiled your model and stored it in 'model' variable\n",
    "\n",
    "# Save the model to an HDF5 file\n",
    "model_cnn.save('malmemcnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1730805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM Attack\n",
    "epsilon = 90 # Perturbation magnitude\n",
    "\n",
    "def fgsm_attack(input_image, epsilon, gradient):\n",
    "    perturbed_image = input_image + epsilon * tf.sign(gradient)\n",
    "    perturbed_image = tf.clip_by_value(perturbed_image, 0, 255)\n",
    "    return perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random test example for the attack\n",
    "random_index = np.random.randint(0, len(X_test_reshaped))\n",
    "test_example = X_test_reshaped[random_index : random_index + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random test example for the attack\n",
    "random_index = np.random.randint(0, len(X_test_reshaped))\n",
    "test_example = X_test_reshaped[random_index : random_index + 1]\n",
    "\n",
    "# Convert the NumPy array to a TensorFlow tensor\n",
    "test_example_tensor = tf.convert_to_tensor(test_example)\n",
    "#test_example_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78366598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gradients\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(test_example_tensor)\n",
    "    prediction = model_cnn(test_example_tensor)\n",
    "    # Convert Pandas Series to NumPy array and reshape\n",
    "    y_test_slice = y_test[random_index : random_index + 1].to_numpy().reshape(prediction.shape)\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_test_slice, prediction)\n",
    "\n",
    "gradient = tape.gradient(loss, test_example_tensor)\n",
    "\n",
    "# Create adversarial example using FGSM\n",
    "adversarial_example = fgsm_attack(test_example_tensor, epsilon, gradient)\n",
    "\n",
    "# Convert the adversarial example back to a NumPy array\n",
    "adversarial_example_np = adversarial_example.numpy()\n",
    "\n",
    "# Evaluate the model on the adversarial example\n",
    "adversarial_accuracy = model_cnn.evaluate(adversarial_example_np, y_test_slice)[1]\n",
    "print(f'Adversarial accuracy: {adversarial_accuracy:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d48d6",
   "metadata": {},
   "source": [
    "JSMA Attack On CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('malmemcnn.h5')\n",
    "\n",
    "# Define the target class for the attack\n",
    "target_class = 0  # Change this to the desired target class index\n",
    "\n",
    "# Define the maximum perturbation limit (epsilon)\n",
    "epsilon = 0.8 # Adjust as needed\n",
    "\n",
    "# Define the number of features in your input data\n",
    "num_features = X_train_reshaped.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the saliency map\n",
    "def compute_saliency_map(input_image, target_class):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        target_probability = prediction[0, target_class]\n",
    "    \n",
    "    gradient = tape.gradient(target_probability, input_image)\n",
    "    saliency_map = tf.abs(gradient)\n",
    "    \n",
    "    return saliency_map\n",
    "# # Define a function to compute the saliency map\n",
    "# def compute_saliency_map(input_image, target_class):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(input_image)\n",
    "#         prediction = model(input_image)\n",
    "#         target_probability = prediction[0, target_class]\n",
    "    \n",
    "#     gradient = tape.gradient(target_probability, input_image)\n",
    "#     saliency_map = tf.abs(gradient)\n",
    "    \n",
    "#     return saliency_map\n",
    "\n",
    "\n",
    "# Define a function to generate adversarial examples using JSMA\n",
    "def jsma_attack(input_image, target_class, epsilon, max_iters=100):\n",
    "    input_image = tf.convert_to_tensor(input_image)\n",
    "    \n",
    "    perturbation = np.zeros_like(input_image)\n",
    "    for _ in range(max_iters):\n",
    "        saliency_map = compute_saliency_map(input_image, target_class)\n",
    "        \n",
    "        # Find the index of the pixel with the highest saliency\n",
    "        max_pixel_index = tf.argmax(saliency_map)\n",
    "        \n",
    "        # Apply perturbation to the pixel with the highest saliency\n",
    "        perturbation[max_pixel_index] += epsilon\n",
    "        \n",
    "        # Apply perturbation to the input image\n",
    "        adversarial_image = input_image + perturbation\n",
    "        \n",
    "        # Check if the attack is successful (changed predicted class)\n",
    "        prediction = model.predict(adversarial_image)\n",
    "        if np.argmax(prediction) != target_class:\n",
    "            break\n",
    "        \n",
    "    return adversarial_image.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0626ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random test example for the attack\n",
    "random_index = np.random.randint(1, len(X_test_reshaped))\n",
    "test_example = X_test_reshaped[random_index : random_index + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e83025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial example using JSMA\n",
    "adversarial_example = jsma_attack(test_example, target_class, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036de78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the adversarial example\n",
    "original_prediction = model.predict(test_example)\n",
    "adversarial_prediction = model.predict(adversarial_example)\n",
    "\n",
    "print(f'Original prediction: {original_prediction}')\n",
    "print(f'Adversarial prediction: {adversarial_prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306cccc",
   "metadata": {},
   "source": [
    "The results you provided indicate the predictions of your model for both the original example and the adversarial example generated using the JSMA attack. Let's break down the meaning of these results:\n",
    "\n",
    "Original prediction: [[1.]]: This line indicates the prediction made by your model on the original input example. In this case, your model predicts a probability of 1.0 for the positive class (class 1). This means that your model is very confident that the input example belongs to the positive class.\n",
    "\n",
    "Adversarial prediction: [[1.]]: This line indicates the prediction made by your model on the adversarial example generated using the JSMA attack. Again, your model predicts a probability of 1.0 for the positive class (class 1). This suggests that even after introducing the adversarial perturbations through the JSMA attack, your model still confidently predicts the positive class for the adversarial example.\n",
    "\n",
    "The result suggests that the JSMA attack might not have been successful in changing the model's prediction from the original class to the targeted class. Adversarial attacks like JSMA can have varying degrees of success depending on the model architecture, the target class, the choice of input features, and the chosen perturbation limits.\n",
    "\n",
    "Keep in mind that obtaining different results might require experimenting with different parameters, such as the target class, epsilon (perturbation limit), and even the specific input example. Additionally, evaluating the adversarial robustness of a model involves testing it on a larger set of examples and measuring the overall success rate of the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8cb5ed",
   "metadata": {},
   "source": [
    "The results you provided indicate the predictions of your model for both the original example and the adversarial example generated using the JSMA attack. Let's analyze the meaning of these results:\n",
    "\n",
    "Original prediction: [[0.00060511]]: This line indicates the prediction made by your model on the original input example. In this case, your model predicts a very low probability of 0.00060511 for the positive class (class 1). This suggests that your model is confident that the input example belongs to the negative class (class 0).\n",
    "\n",
    "Adversarial prediction: [[1.]]: This line indicates the prediction made by your model on the adversarial example generated using the JSMA attack. Your model predicts a probability of 1.0 for the positive class (class 1) for the adversarial example. This means that, after applying the JSMA attack, your model now confidently predicts the positive class for the adversarial example, even though it originally predicted the negative class for the original example.\n",
    "\n",
    "The result indicates that the JSMA attack was successful in changing the model's prediction from the negative class to the positive class for the adversarial example. This shift in prediction shows that the adversarial perturbations introduced by the JSMA attack were able to deceive the model and lead it to misclassify the example.\n",
    "\n",
    "This result highlights the susceptibility of your model to adversarial attacks and the importance of developing robust machine learning models that can handle such manipulations effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of epsilon values\n",
    "epsilon_values = np.linspace(0, 100, num=10)\n",
    "\n",
    "# Initialize an array to store success rates for each epsilon\n",
    "success_rates = []\n",
    "\n",
    "# Iterate through each epsilon value\n",
    "for epsilon in epsilon_values:\n",
    "    # Generate adversarial example using JSMA\n",
    "    adversarial_example = jsma_attack(test_example, target_class, epsilon)\n",
    "    \n",
    "    # Evaluate the model on the adversarial example\n",
    "    adversarial_prediction = model.predict(adversarial_example)\n",
    "    \n",
    "    # Check if the attack is successful (changed predicted class)\n",
    "    if np.argmax(adversarial_prediction) != target_class:\n",
    "        success_rates.append(1)  # Attack successful\n",
    "    else:\n",
    "        success_rates.append(0)  # Attack unsuccessful\n",
    "\n",
    "# Plot the security evaluation curve\n",
    "plt.plot(epsilon_values, success_rates, marker='o')\n",
    "plt.xlabel('Epsilon (Perturbation)')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.title('Security Evaluation Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
